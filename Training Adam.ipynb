{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 24, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_convolution (Conv2D)      (None, 12, 12, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (MaxPooling2D)            (None, 6, 6, 64)     0           conv1_convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_convolution (Conv2D)      (None, 3, 3, 192)    110784      conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (MaxPooling2D)            (None, 3, 3, 192)    0           conv2_convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 3, 64)     12352       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 64)     12352       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 3, 3, 192)    0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 3, 3, 64)     12352       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 3, 3, 64)     36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 64)     102464      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 64)     12352       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception3a_activation (Concate (None, 3, 3, 256)    0           conv2d[0][0]                     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 3, 3, 256)    0           inception3a_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 120)    30840       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 120)    30840       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 3, 3, 256)    0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 120)    30840       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 120)    129720      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 3, 3, 120)    360120      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 3, 3, 120)    30840       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 480)    0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3, 3, 480)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inception3 (MaxPooling2D)       (None, 3, 3, 480)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 128)    147584      conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 128)    409728      conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 128)    61568       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 3, 3, 128)    147584      conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 3, 3, 128)    409728      conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 3, 3, 128)    61568       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 3, 3, 128)    147584      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 3, 3, 128)    409728      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 3, 3, 128)    61568       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 3, 3, 128)    147584      conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 3, 3, 128)    409728      conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 3, 3, 128)    61568       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception4c_activation_branch_2 (None, 3, 3, 512)    0           conv2d_72[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4d_activation_branch_3 (None, 3, 3, 512)    0           conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inception4a_activation_trunk (C (None, 3, 3, 512)    0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4b_activation_branch_1 (None, 3, 3, 512)    0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 3, 3, 512)    0           inception4c_activation_branch_2[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 3, 3, 512)    0           inception4d_activation_branch_3[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 3, 3, 512)    0           inception4a_activation_trunk[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 3, 3, 512)    0           inception4b_activation_branch_1[0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 132)    67716       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 132)    67716       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 3, 3, 512)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 3, 3, 132)    67716       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 3, 3, 132)    67716       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 3, 3, 512)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 3, 3, 132)    67716       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 3, 3, 132)    67716       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 512)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 3, 3, 132)    67716       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 3, 3, 132)    67716       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 512)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 132)    67716       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 132)    156948      conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 132)    435732      conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 132)    67716       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 3, 3, 132)    67716       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 3, 3, 132)    156948      conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 3, 3, 132)    435732      conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 3, 3, 132)    67716       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 3, 3, 132)    67716       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 3, 3, 132)    156948      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 3, 3, 132)    435732      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 3, 3, 132)    67716       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 3, 3, 132)    67716       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 3, 3, 132)    156948      conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 3, 3, 132)    435732      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 3, 3, 132)    67716       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_branch_2 (None, 3, 3, 528)    0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_branch_3 (None, 3, 3, 528)    0           conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_trunk (C (None, 3, 3, 528)    0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_branch_1 (None, 3, 3, 528)    0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 3, 3, 528)    0           inception4e_activation_branch_2[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 3, 3, 528)    0           inception4e_activation_branch_3[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 3, 3, 528)    0           inception4e_activation_trunk[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3, 3, 528)    0           inception4e_activation_branch_1[0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 208)    110032      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 208)    110032      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 3, 3, 528)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 3, 3, 208)    110032      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 3, 3, 208)    110032      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 3, 3, 528)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 3, 3, 208)    110032      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 3, 3, 208)    110032      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 528)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 3, 3, 208)    110032      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 3, 3, 208)    110032      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 3, 3, 528)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 208)    110032      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 208)    110032      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 3, 3, 208)    110032      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 3, 3, 208)    389584      conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 3, 3, 208)    1081808     conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 3, 3, 208)    110032      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 3, 3, 208)    110032      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 3, 3, 208)    110032      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 3, 3, 208)    110032      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 3, 3, 208)    110032      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 832)    0           conv2d_84[0][0]                  \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 3, 832)    0           conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "                                                                 conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 832)    0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 832)    0           conv2d_54[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 3, 3, 832)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 3, 3, 832)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 3, 3, 832)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3, 3, 832)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception4_branch_2 (MaxPooling (None, 3, 3, 832)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception4_branch_3 (MaxPooling (None, 3, 3, 832)    0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception4_trunk (MaxPooling2D) (None, 3, 3, 832)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception4_branch_1 (MaxPooling (None, 3, 3, 832)    0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 3, 3, 832)    0           inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 3, 3, 208)    173264      inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 3, 3, 208)    173264      inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 3, 3, 832)    0           inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 3, 3, 208)    173264      inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 3, 3, 208)    173264      inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 832)    0           inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 3, 3, 832)    0           inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 3, 3, 208)    173264      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 3, 3, 208)    173264      inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 3, 3, 208)    389584      conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 3, 3, 208)    1081808     conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 3, 3, 208)    173264      max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 3, 3, 208)    173264      inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 3, 3, 208)    173264      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 3, 3, 208)    173264      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_branch_2 (None, 3, 3, 832)    0           conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_branch_3 (None, 3, 3, 832)    0           conv2d_120[0][0]                 \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_trunk (C (None, 3, 3, 832)    0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_branch_1 (None, 3, 3, 832)    0           conv2d_60[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 3, 3, 832)    0           inception5a_activation_branch_2[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 3, 3, 832)    0           inception5a_activation_branch_3[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 3, 3, 832)    0           inception5a_activation_trunk[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 3, 3, 832)    0           inception5a_activation_branch_1[0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 3, 3, 256)    213248      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 3, 3, 256)    213248      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 3, 3, 832)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 3, 3, 256)    213248      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 3, 3, 256)    213248      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 3, 3, 832)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 3, 3, 256)    213248      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 3, 3, 256)    213248      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 832)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 3, 3, 256)    213248      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 3, 3, 256)    213248      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 832)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 3, 3, 256)    213248      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 3, 3, 256)    590080      conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 3, 3, 256)    1638656     conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 3, 3, 256)    213248      max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 3, 3, 256)    213248      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 3, 3, 256)    590080      conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 3, 3, 256)    1638656     conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 3, 3, 256)    213248      max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 3, 3, 256)    213248      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 3, 3, 256)    590080      conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 3, 3, 256)    1638656     conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 3, 3, 256)    213248      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 3, 3, 256)    213248      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 3, 3, 256)    590080      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 3, 3, 256)    1638656     conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 256)    213248      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_126[0][0]                 \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 3, 3, 1024)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 3, 3, 1024)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 3, 3, 1024)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 3, 3, 1024)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_3_branch_2 (MaxPool (None, 3, 3, 1024)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_4_branch_3 (MaxPool (None, 3, 3, 1024)   0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_1_trunk (MaxPooling (None, 3, 3, 1024)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_2_branch_1 (MaxPool (None, 3, 3, 1024)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 6, 3, 1024)   0           inception5b_3_branch_2[0][0]     \n",
      "                                                                 inception5b_4_branch_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 12, 3, 1024)  0           inception5b_1_trunk[0][0]        \n",
      "                                                                 inception5b_2_branch_1[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 36864)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           2359360     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1591)         103415      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1591)         0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,684,327\n",
      "Trainable params: 38,684,327\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 424961 images belonging to 1591 classes.\n",
      "Found 120531 images belonging to 1591 classes.\n",
      "training: \n",
      "Epoch 1/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 1.2217 - acc: 0.6865\n",
      "Epoch 00001: val_loss improved from inf to 0.27796, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3936s 296ms/step - loss: 1.2217 - acc: 0.6865 - val_loss: 0.2780 - val_acc: 0.9350\n",
      "Epoch 2/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 1.0189 - acc: 0.7314\n",
      "Epoch 00002: val_loss improved from 0.27796 to 0.20918, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3853s 290ms/step - loss: 1.0189 - acc: 0.7314 - val_loss: 0.2092 - val_acc: 0.9600\n",
      "Epoch 3/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8675 - acc: 0.7665\n",
      "Epoch 00003: val_loss improved from 0.20918 to 0.13835, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3853s 290ms/step - loss: 0.8675 - acc: 0.7665 - val_loss: 0.1384 - val_acc: 0.9700\n",
      "Epoch 4/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7463 - acc: 0.7966\n",
      "Epoch 00004: val_loss did not improve from 0.13835\n",
      "13280/13280 [==============================] - 3850s 290ms/step - loss: 0.7463 - acc: 0.7966 - val_loss: 0.1401 - val_acc: 0.9700\n",
      "Epoch 5/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6517 - acc: 0.8198\n",
      "Epoch 00005: val_loss improved from 0.13835 to 0.11456, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3854s 290ms/step - loss: 0.6517 - acc: 0.8198 - val_loss: 0.1146 - val_acc: 0.9800\n",
      "Epoch 6/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5798 - acc: 0.8393\n",
      "Epoch 00006: val_loss improved from 0.11456 to 0.07765, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3850s 290ms/step - loss: 0.5798 - acc: 0.8393 - val_loss: 0.0777 - val_acc: 0.9850\n",
      "Epoch 7/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8541\n",
      "Epoch 00007: val_loss improved from 0.07765 to 0.04599, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3848s 290ms/step - loss: 0.5205 - acc: 0.8541 - val_loss: 0.0460 - val_acc: 0.9900\n",
      "Epoch 8/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4649 - acc: 0.8693\n",
      "Epoch 00008: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.4649 - acc: 0.8694 - val_loss: 0.0592 - val_acc: 0.9850\n",
      "Epoch 9/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8815\n",
      "Epoch 00009: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3847s 290ms/step - loss: 0.4235 - acc: 0.8815 - val_loss: 0.0568 - val_acc: 0.9900\n",
      "Epoch 10/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8923\n",
      "Epoch 00010: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3844s 289ms/step - loss: 0.3837 - acc: 0.8923 - val_loss: 0.1524 - val_acc: 0.9787\n",
      "Epoch 11/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.9010\n",
      "Epoch 00011: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.3514 - acc: 0.9010 - val_loss: 0.0874 - val_acc: 0.9850\n",
      "Epoch 12/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.3296 - acc: 0.9074\n",
      "Epoch 00012: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.3296 - acc: 0.9074 - val_loss: 0.1004 - val_acc: 0.9887\n",
      "Epoch 13/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.9128\n",
      "Epoch 00013: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.3127 - acc: 0.9128 - val_loss: 0.0826 - val_acc: 0.9912\n",
      "Epoch 14/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2981 - acc: 0.9165\n",
      "Epoch 00014: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3847s 290ms/step - loss: 0.2981 - acc: 0.9165 - val_loss: 0.0568 - val_acc: 0.9937\n",
      "Epoch 15/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.9211\n",
      "Epoch 00015: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3843s 289ms/step - loss: 0.2839 - acc: 0.9211 - val_loss: 0.0795 - val_acc: 0.9912\n",
      "Epoch 16/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9268\n",
      "Epoch 00016: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.2663 - acc: 0.9268 - val_loss: 0.1064 - val_acc: 0.9887\n",
      "Epoch 17/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.9331\n",
      "Epoch 00017: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.2436 - acc: 0.9331 - val_loss: 0.0630 - val_acc: 0.9875\n",
      "Epoch 18/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9364\n",
      "Epoch 00018: val_loss did not improve from 0.04599\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.2342 - acc: 0.9364 - val_loss: 0.1011 - val_acc: 0.9887\n",
      "Epoch 19/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2268 - acc: 0.9388\n",
      "Epoch 00019: val_loss improved from 0.04599 to 0.04294, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3851s 290ms/step - loss: 0.2268 - acc: 0.9388 - val_loss: 0.0429 - val_acc: 0.9900\n",
      "Epoch 20/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9416\n",
      "Epoch 00020: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3844s 289ms/step - loss: 0.2188 - acc: 0.9416 - val_loss: 0.0893 - val_acc: 0.9825\n",
      "Epoch 21/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9426\n",
      "Epoch 00021: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3843s 289ms/step - loss: 0.2150 - acc: 0.9426 - val_loss: 0.1217 - val_acc: 0.9925\n",
      "Epoch 22/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9434\n",
      "Epoch 00022: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3849s 290ms/step - loss: 0.2115 - acc: 0.9434 - val_loss: 0.0757 - val_acc: 0.9875\n",
      "Epoch 23/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9459\n",
      "Epoch 00023: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.2019 - acc: 0.9459 - val_loss: 0.0562 - val_acc: 0.9925\n",
      "Epoch 24/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9467\n",
      "Epoch 00024: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3849s 290ms/step - loss: 0.2032 - acc: 0.9467 - val_loss: 0.0510 - val_acc: 0.9900\n",
      "Epoch 25/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9471\n",
      "Epoch 00025: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3843s 289ms/step - loss: 0.1990 - acc: 0.9471 - val_loss: 0.1230 - val_acc: 0.9912\n",
      "Epoch 26/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9471\n",
      "Epoch 00026: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.2022 - acc: 0.9471 - val_loss: 0.1541 - val_acc: 0.9925\n",
      "Epoch 27/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1968 - acc: 0.9486\n",
      "Epoch 00027: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.1969 - acc: 0.9486 - val_loss: 0.0789 - val_acc: 0.9887\n",
      "Epoch 28/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9492\n",
      "Epoch 00028: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.1960 - acc: 0.9492 - val_loss: 0.0715 - val_acc: 0.9912\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1904 - acc: 0.9507\n",
      "Epoch 00029: val_loss did not improve from 0.04294\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.1904 - acc: 0.9507 - val_loss: 0.0816 - val_acc: 0.9912\n",
      "Epoch 30/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9503\n",
      "Epoch 00030: val_loss improved from 0.04294 to 0.03386, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3848s 290ms/step - loss: 0.1958 - acc: 0.9503 - val_loss: 0.0339 - val_acc: 0.9925\n",
      "Epoch 31/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9516\n",
      "Epoch 00031: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3843s 289ms/step - loss: 0.1885 - acc: 0.9516 - val_loss: 0.0491 - val_acc: 0.9912\n",
      "Epoch 32/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1903 - acc: 0.9517\n",
      "Epoch 00032: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.1903 - acc: 0.9517 - val_loss: 0.0390 - val_acc: 0.9912\n",
      "Epoch 33/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9520\n",
      "Epoch 00033: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3843s 289ms/step - loss: 0.1866 - acc: 0.9520 - val_loss: 0.0866 - val_acc: 0.9825\n",
      "Epoch 34/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1840 - acc: 0.9530\n",
      "Epoch 00034: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3846s 290ms/step - loss: 0.1839 - acc: 0.9530 - val_loss: 0.1187 - val_acc: 0.9875\n",
      "Epoch 35/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9530\n",
      "Epoch 00035: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3844s 289ms/step - loss: 0.1820 - acc: 0.9530 - val_loss: 0.1106 - val_acc: 0.9875\n",
      "Epoch 36/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1852 - acc: 0.9532\n",
      "Epoch 00036: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3844s 289ms/step - loss: 0.1852 - acc: 0.9532 - val_loss: 0.1132 - val_acc: 0.9825\n",
      "Epoch 37/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9541\n",
      "Epoch 00037: val_loss did not improve from 0.03386\n",
      "13280/13280 [==============================] - 3841s 289ms/step - loss: 0.1831 - acc: 0.9541 - val_loss: 0.0999 - val_acc: 0.9912\n",
      "Epoch 38/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9535\n",
      "Epoch 00038: val_loss improved from 0.03386 to 0.02273, saving model to tbe_cnn_ytd_adam.h5\n",
      "13280/13280 [==============================] - 3847s 290ms/step - loss: 0.1863 - acc: 0.9535 - val_loss: 0.0227 - val_acc: 0.9937\n",
      "Epoch 39/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9542\n",
      "Epoch 00039: val_loss did not improve from 0.02273\n",
      "13280/13280 [==============================] - 3845s 290ms/step - loss: 0.1801 - acc: 0.9542 - val_loss: 0.0858 - val_acc: 0.9887\n",
      "Epoch 40/40\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9545\n",
      "Epoch 00040: val_loss did not improve from 0.02273\n",
      "13280/13280 [==============================] - 3844s 289ms/step - loss: 0.1850 - acc: 0.9545 - val_loss: 0.1146 - val_acc: 0.9900\n",
      "Common Function\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import model_3_branch\n",
    "import common_function\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import os\n",
    "import asyncio\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.models import load_model, Model\n",
    "\n",
    "# Just disables the warning, doesn't enable AVX/FMA (no GPU)\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "epochs = 40\n",
    "l_rate = 1.0e-4\n",
    "decay = l_rate / epochs\n",
    "adam = Adam(lr=l_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "batch_size = 32\n",
    "img_width, img_height = 24, 24\n",
    "path_data_set = './ytd'\n",
    "input_img, merged = model_3_branch.get_model(img_width, img_height)\n",
    "num_train_images = 424961  # training images: 424961  # total images: 605855\n",
    "file_path = 'tbe_cnn_ytd_adam.h5'\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "\n",
    "############################################### Training Dataset #############################################################\n",
    "\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    flatten = Flatten()(merged)\n",
    "    dense = Dense(64)(flatten)\n",
    "    activation = Activation('softmax')(dense)\n",
    "    dropout = Dropout(0.5)(activation)\n",
    "    dense = Dense(1591)(dropout)\n",
    "    activation = Activation('softmax')(dense)\n",
    "\n",
    "    base_model = Model(input_img, activation)\n",
    "else:\n",
    "    base_model = load_model(file_path)\n",
    "    # base_model.load_weights(file_path)\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "train_generator_lr = datagen.flow_from_directory(\n",
    "    str(path_data_set + '/train'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator_lr = datagen.flow_from_directory(\n",
    "    str(path_data_set + '/validate'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print('training: ')\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    file_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='auto',\n",
    "    verbose=1\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = base_model.fit_generator(\n",
    "    generator=train_generator_lr,\n",
    "    steps_per_epoch=num_train_images // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator_lr,\n",
    "    validation_steps=800 // batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "common_func = common_function.CommonFunction()\n",
    "common_func.plot_training(history, 'TBE-CNN (Adam)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
