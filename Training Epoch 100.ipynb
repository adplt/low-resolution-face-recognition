{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/atriadplt2/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 24, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_convolution (Conv2D)      (None, 12, 12, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (MaxPooling2D)            (None, 6, 6, 64)     0           conv1_convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_convolution (Conv2D)      (None, 3, 3, 192)    110784      conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (MaxPooling2D)            (None, 3, 3, 192)    0           conv2_convolution[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 3, 3, 64)     12352       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 3, 3, 64)     12352       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 3, 3, 192)    0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 3, 3, 64)     12352       conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 3, 3, 64)     36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 3, 64)     102464      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 3, 3, 64)     12352       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception3a_activation (Concate (None, 3, 3, 256)    0           conv2d[0][0]                     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 3, 3, 256)    0           inception3a_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 120)    30840       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 120)    30840       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 3, 3, 256)    0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 3, 3, 120)    30840       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 120)    129720      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 3, 3, 120)    360120      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 3, 3, 120)    30840       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 480)    0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3, 3, 480)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inception3 (MaxPooling2D)       (None, 3, 3, 480)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 480)    0           inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 128)    147584      conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 128)    409728      conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 128)    61568       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 3, 3, 128)    147584      conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 3, 3, 128)    409728      conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 3, 3, 128)    61568       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 3, 3, 128)    147584      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 3, 3, 128)    409728      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 3, 3, 128)    61568       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 3, 3, 128)    61568       inception3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 3, 3, 128)    147584      conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 3, 3, 128)    409728      conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 3, 3, 128)    61568       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception4c_activation_branch_2 (None, 3, 3, 512)    0           conv2d_72[0][0]                  \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4d_activation_branch_3 (None, 3, 3, 512)    0           conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inception4a_activation_trunk (C (None, 3, 3, 512)    0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4b_activation_branch_1 (None, 3, 3, 512)    0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 3, 3, 512)    0           inception4c_activation_branch_2[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 3, 3, 512)    0           inception4d_activation_branch_3[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 3, 3, 512)    0           inception4a_activation_trunk[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 3, 3, 512)    0           inception4b_activation_branch_1[0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 132)    67716       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 132)    67716       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 3, 3, 512)    0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 3, 3, 132)    67716       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 3, 3, 132)    67716       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 3, 3, 512)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 3, 3, 132)    67716       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 3, 3, 132)    67716       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 512)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 3, 3, 132)    67716       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 3, 3, 132)    67716       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 512)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 132)    67716       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 132)    156948      conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 132)    435732      conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 132)    67716       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 3, 3, 132)    67716       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 3, 3, 132)    156948      conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 3, 3, 132)    435732      conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 3, 3, 132)    67716       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 3, 3, 132)    67716       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 3, 3, 132)    156948      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 3, 3, 132)    435732      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 3, 3, 132)    67716       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 3, 3, 132)    67716       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 3, 3, 132)    156948      conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 3, 3, 132)    435732      conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 3, 3, 132)    67716       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_branch_2 (None, 3, 3, 528)    0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_branch_3 (None, 3, 3, 528)    0           conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_trunk (C (None, 3, 3, 528)    0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception4e_activation_branch_1 (None, 3, 3, 528)    0           conv2d_48[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 3, 3, 528)    0           inception4e_activation_branch_2[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 3, 3, 528)    0           inception4e_activation_branch_3[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 3, 3, 528)    0           inception4e_activation_trunk[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3, 3, 528)    0           inception4e_activation_branch_1[0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 208)    110032      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 208)    110032      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 3, 3, 528)    0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 3, 3, 208)    110032      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 3, 3, 208)    110032      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 3, 3, 528)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 3, 3, 208)    110032      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 3, 3, 208)    110032      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 528)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 3, 3, 208)    110032      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 3, 3, 208)    110032      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 3, 3, 528)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 208)    110032      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 208)    110032      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 3, 3, 208)    110032      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 3, 3, 208)    389584      conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 3, 3, 208)    1081808     conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 3, 3, 208)    110032      max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 3, 3, 208)    110032      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 3, 3, 208)    110032      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 3, 3, 208)    110032      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 3, 3, 208)    110032      max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 832)    0           conv2d_84[0][0]                  \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 3, 832)    0           conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "                                                                 conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 832)    0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 832)    0           conv2d_54[0][0]                  \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 3, 3, 832)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 3, 3, 832)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 3, 3, 832)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3, 3, 832)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception4_branch_2 (MaxPooling (None, 3, 3, 832)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception4_branch_3 (MaxPooling (None, 3, 3, 832)    0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception4_trunk (MaxPooling2D) (None, 3, 3, 832)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception4_branch_1 (MaxPooling (None, 3, 3, 832)    0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 3, 3, 832)    0           inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 3, 3, 208)    173264      inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 3, 3, 208)    173264      inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 3, 3, 832)    0           inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 3, 3, 208)    173264      inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 3, 3, 208)    173264      inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 832)    0           inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 3, 3, 832)    0           inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 3, 3, 208)    173264      max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 3, 3, 208)    173264      inception4_branch_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 3, 3, 208)    389584      conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 3, 3, 208)    1081808     conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 3, 3, 208)    173264      max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 3, 3, 208)    173264      inception4_trunk[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 3, 3, 208)    173264      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 3, 3, 208)    173264      inception4_branch_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 3, 3, 208)    389584      conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 3, 3, 208)    1081808     conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 3, 3, 208)    173264      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_branch_2 (None, 3, 3, 832)    0           conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_branch_3 (None, 3, 3, 832)    0           conv2d_120[0][0]                 \n",
      "                                                                 conv2d_122[0][0]                 \n",
      "                                                                 conv2d_124[0][0]                 \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_trunk (C (None, 3, 3, 832)    0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception5a_activation_branch_1 (None, 3, 3, 832)    0           conv2d_60[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 3, 3, 832)    0           inception5a_activation_branch_2[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 3, 3, 832)    0           inception5a_activation_branch_3[0\n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 3, 3, 832)    0           inception5a_activation_trunk[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 3, 3, 832)    0           inception5a_activation_branch_1[0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 3, 3, 256)    213248      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 3, 3, 256)    213248      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 3, 3, 832)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 3, 3, 256)    213248      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 3, 3, 256)    213248      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 3, 3, 832)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 3, 3, 256)    213248      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 3, 3, 256)    213248      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 832)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 3, 3, 256)    213248      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 3, 3, 256)    213248      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 832)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 3, 3, 256)    213248      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 3, 3, 256)    590080      conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 3, 3, 256)    1638656     conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 3, 3, 256)    213248      max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 3, 3, 256)    213248      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 3, 3, 256)    590080      conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 3, 3, 256)    1638656     conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 3, 3, 256)    213248      max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 3, 3, 256)    213248      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 3, 3, 256)    590080      conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 3, 3, 256)    1638656     conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 3, 3, 256)    213248      max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 3, 3, 256)    213248      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 3, 3, 256)    590080      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 3, 3, 256)    1638656     conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 256)    213248      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_126[0][0]                 \n",
      "                                                                 conv2d_128[0][0]                 \n",
      "                                                                 conv2d_130[0][0]                 \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 1024)   0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 3, 3, 1024)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 3, 3, 1024)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 3, 3, 1024)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 3, 3, 1024)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_3_branch_2 (MaxPool (None, 3, 3, 1024)   0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_4_branch_3 (MaxPool (None, 3, 3, 1024)   0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_1_trunk (MaxPooling (None, 3, 3, 1024)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception5b_2_branch_1 (MaxPool (None, 3, 3, 1024)   0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 6, 3, 1024)   0           inception5b_3_branch_2[0][0]     \n",
      "                                                                 inception5b_4_branch_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 12, 3, 1024)  0           inception5b_1_trunk[0][0]        \n",
      "                                                                 inception5b_2_branch_1[0][0]     \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 36864)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           2359360     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1591)         103415      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1591)         0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,684,327\n",
      "Trainable params: 38,684,327\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 424961 images belonging to 1591 classes.\n",
      "Found 120531 images belonging to 1591 classes.\n",
      "training: \n",
      "Epoch 1/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8817 - acc: 0.7534\n",
      "Epoch 00001: val_loss improved from inf to 0.17698, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3208s 242ms/step - loss: 0.8817 - acc: 0.7534 - val_loss: 0.1770 - val_acc: 0.9725\n",
      "Epoch 2/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8663 - acc: 0.7571\n",
      "Epoch 00002: val_loss improved from 0.17698 to 0.17596, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.8662 - acc: 0.7571 - val_loss: 0.1760 - val_acc: 0.9725\n",
      "Epoch 3/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8588 - acc: 0.7592\n",
      "Epoch 00003: val_loss improved from 0.17596 to 0.15299, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3164s 238ms/step - loss: 0.8588 - acc: 0.7592 - val_loss: 0.1530 - val_acc: 0.9800\n",
      "Epoch 4/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8455 - acc: 0.7611\n",
      "Epoch 00004: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.8454 - acc: 0.7611 - val_loss: 0.1556 - val_acc: 0.9762\n",
      "Epoch 5/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8402 - acc: 0.7619\n",
      "Epoch 00005: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.8402 - acc: 0.7619 - val_loss: 0.1635 - val_acc: 0.9712\n",
      "Epoch 6/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8295 - acc: 0.7648\n",
      "Epoch 00006: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3154s 237ms/step - loss: 0.8295 - acc: 0.7648 - val_loss: 0.1684 - val_acc: 0.9762\n",
      "Epoch 7/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8199 - acc: 0.7670\n",
      "Epoch 00007: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.8199 - acc: 0.7670 - val_loss: 0.1563 - val_acc: 0.9762\n",
      "Epoch 8/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.8091 - acc: 0.7697\n",
      "Epoch 00008: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.8091 - acc: 0.7697 - val_loss: 0.1658 - val_acc: 0.9737\n",
      "Epoch 9/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7963 - acc: 0.7726\n",
      "Epoch 00009: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.7963 - acc: 0.7726 - val_loss: 0.1547 - val_acc: 0.9737\n",
      "Epoch 10/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7895 - acc: 0.7746\n",
      "Epoch 00010: val_loss did not improve from 0.15299\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.7895 - acc: 0.7746 - val_loss: 0.1576 - val_acc: 0.9688\n",
      "Epoch 11/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7778 - acc: 0.7783\n",
      "Epoch 00011: val_loss improved from 0.15299 to 0.13963, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3162s 238ms/step - loss: 0.7778 - acc: 0.7783 - val_loss: 0.1396 - val_acc: 0.9725\n",
      "Epoch 12/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7710 - acc: 0.7788\n",
      "Epoch 00012: val_loss did not improve from 0.13963\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.7710 - acc: 0.7788 - val_loss: 0.1587 - val_acc: 0.9737\n",
      "Epoch 13/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7633 - acc: 0.7807\n",
      "Epoch 00013: val_loss did not improve from 0.13963\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.7633 - acc: 0.7807 - val_loss: 0.1436 - val_acc: 0.9737\n",
      "Epoch 14/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7534 - acc: 0.7828\n",
      "Epoch 00014: val_loss did not improve from 0.13963\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.7534 - acc: 0.7828 - val_loss: 0.1426 - val_acc: 0.9737\n",
      "Epoch 15/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7480 - acc: 0.7849\n",
      "Epoch 00015: val_loss improved from 0.13963 to 0.12241, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3161s 238ms/step - loss: 0.7480 - acc: 0.7849 - val_loss: 0.1224 - val_acc: 0.9762\n",
      "Epoch 16/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7371 - acc: 0.7874\n",
      "Epoch 00016: val_loss did not improve from 0.12241\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.7370 - acc: 0.7874 - val_loss: 0.1268 - val_acc: 0.9825\n",
      "Epoch 17/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7318 - acc: 0.7885\n",
      "Epoch 00017: val_loss did not improve from 0.12241\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.7319 - acc: 0.7885 - val_loss: 0.1325 - val_acc: 0.9775\n",
      "Epoch 18/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7243 - acc: 0.7905\n",
      "Epoch 00018: val_loss improved from 0.12241 to 0.11788, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.7243 - acc: 0.7905 - val_loss: 0.1179 - val_acc: 0.9775\n",
      "Epoch 19/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7150 - acc: 0.7929\n",
      "Epoch 00019: val_loss did not improve from 0.11788\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.7150 - acc: 0.7929 - val_loss: 0.1216 - val_acc: 0.9850\n",
      "Epoch 20/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7119 - acc: 0.7928\n",
      "Epoch 00020: val_loss did not improve from 0.11788\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.7119 - acc: 0.7928 - val_loss: 0.1222 - val_acc: 0.9812\n",
      "Epoch 21/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.7029 - acc: 0.7958\n",
      "Epoch 00021: val_loss did not improve from 0.11788\n",
      "13280/13280 [==============================] - 3163s 238ms/step - loss: 0.7029 - acc: 0.7958 - val_loss: 0.1272 - val_acc: 0.9837\n",
      "Epoch 22/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6970 - acc: 0.7969\n",
      "Epoch 00022: val_loss did not improve from 0.11788\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.6970 - acc: 0.7969 - val_loss: 0.1384 - val_acc: 0.9837\n",
      "Epoch 23/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6863 - acc: 0.7995\n",
      "Epoch 00023: val_loss improved from 0.11788 to 0.11288, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3162s 238ms/step - loss: 0.6863 - acc: 0.7995 - val_loss: 0.1129 - val_acc: 0.9825\n",
      "Epoch 24/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6834 - acc: 0.8002\n",
      "Epoch 00024: val_loss did not improve from 0.11288\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.6834 - acc: 0.8002 - val_loss: 0.1315 - val_acc: 0.9787\n",
      "Epoch 25/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6818 - acc: 0.8011\n",
      "Epoch 00025: val_loss did not improve from 0.11288\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.6818 - acc: 0.8011 - val_loss: 0.1188 - val_acc: 0.9825\n",
      "Epoch 26/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6738 - acc: 0.8022\n",
      "Epoch 00026: val_loss did not improve from 0.11288\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.6738 - acc: 0.8022 - val_loss: 0.1142 - val_acc: 0.9812\n",
      "Epoch 27/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6644 - acc: 0.8054\n",
      "Epoch 00027: val_loss did not improve from 0.11288\n",
      "13280/13280 [==============================] - 3154s 237ms/step - loss: 0.6644 - acc: 0.8054 - val_loss: 0.1147 - val_acc: 0.9850\n",
      "Epoch 28/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6615 - acc: 0.8061\n",
      "Epoch 00028: val_loss improved from 0.11288 to 0.10714, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.6615 - acc: 0.8061 - val_loss: 0.1071 - val_acc: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6539 - acc: 0.8078\n",
      "Epoch 00029: val_loss did not improve from 0.10714\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.6539 - acc: 0.8078 - val_loss: 0.1136 - val_acc: 0.9875\n",
      "Epoch 30/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6491 - acc: 0.8095\n",
      "Epoch 00030: val_loss improved from 0.10714 to 0.10631, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3168s 239ms/step - loss: 0.6491 - acc: 0.8095 - val_loss: 0.1063 - val_acc: 0.9875\n",
      "Epoch 31/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6419 - acc: 0.8106\n",
      "Epoch 00031: val_loss improved from 0.10631 to 0.08600, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3164s 238ms/step - loss: 0.6419 - acc: 0.8106 - val_loss: 0.0860 - val_acc: 0.9862\n",
      "Epoch 32/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6414 - acc: 0.8108\n",
      "Epoch 00032: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.6414 - acc: 0.8108 - val_loss: 0.1049 - val_acc: 0.9850\n",
      "Epoch 33/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6388 - acc: 0.8121\n",
      "Epoch 00033: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.6388 - acc: 0.8121 - val_loss: 0.0977 - val_acc: 0.9862\n",
      "Epoch 34/100\n",
      " 5644/13280 [===========>..................] - ETA: 30:15 - loss: 0.6289 - acc: 0.8144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6310 - acc: 0.8135\n",
      "Epoch 00034: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.6310 - acc: 0.8135 - val_loss: 0.1091 - val_acc: 0.9800\n",
      "Epoch 35/100\n",
      "  809/13280 [>.............................] - ETA: 49:19 - loss: 0.6262 - acc: 0.8136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8958/13280 [===================>..........] - ETA: 17:05 - loss: 0.6276 - acc: 0.8144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6280 - acc: 0.8145\n",
      "Epoch 00035: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3154s 237ms/step - loss: 0.6280 - acc: 0.8145 - val_loss: 0.1049 - val_acc: 0.9837\n",
      "Epoch 36/100\n",
      " 6044/13280 [============>.................] - ETA: 28:40 - loss: 0.6203 - acc: 0.8163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6202 - acc: 0.8167\n",
      "Epoch 00036: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.6202 - acc: 0.8167 - val_loss: 0.1057 - val_acc: 0.9875\n",
      "Epoch 37/100\n",
      " 1114/13280 [=>............................] - ETA: 48:10 - loss: 0.6218 - acc: 0.8164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8077/13280 [=================>............] - ETA: 20:35 - loss: 0.6192 - acc: 0.8170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6178 - acc: 0.8172\n",
      "Epoch 00037: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.6178 - acc: 0.8172 - val_loss: 0.1171 - val_acc: 0.9887\n",
      "Epoch 38/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.8183\n",
      "Epoch 00038: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.6151 - acc: 0.8184 - val_loss: 0.1157 - val_acc: 0.9862\n",
      "Epoch 39/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.8193\n",
      "Epoch 00039: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3163s 238ms/step - loss: 0.6091 - acc: 0.8193 - val_loss: 0.0902 - val_acc: 0.9825\n",
      "Epoch 40/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6058 - acc: 0.8199\n",
      "Epoch 00040: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.6058 - acc: 0.8199 - val_loss: 0.1083 - val_acc: 0.9837\n",
      "Epoch 41/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.8216\n",
      "Epoch 00041: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.6016 - acc: 0.8216 - val_loss: 0.1087 - val_acc: 0.9850\n",
      "Epoch 42/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5969 - acc: 0.8224\n",
      "Epoch 00042: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.5969 - acc: 0.8224 - val_loss: 0.0977 - val_acc: 0.9825\n",
      "Epoch 43/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5942 - acc: 0.8232\n",
      "Epoch 00043: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3162s 238ms/step - loss: 0.5942 - acc: 0.8232 - val_loss: 0.0880 - val_acc: 0.9887\n",
      "Epoch 44/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5906 - acc: 0.8240\n",
      "Epoch 00044: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3162s 238ms/step - loss: 0.5906 - acc: 0.8240 - val_loss: 0.0963 - val_acc: 0.9862\n",
      "Epoch 45/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5828 - acc: 0.8263\n",
      "Epoch 00045: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3163s 238ms/step - loss: 0.5828 - acc: 0.8263 - val_loss: 0.1040 - val_acc: 0.9837\n",
      "Epoch 46/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.8267\n",
      "Epoch 00046: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5822 - acc: 0.8267 - val_loss: 0.0994 - val_acc: 0.9837\n",
      "Epoch 47/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5810 - acc: 0.8267\n",
      "Epoch 00047: val_loss did not improve from 0.08600\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5810 - acc: 0.8267 - val_loss: 0.0937 - val_acc: 0.9837\n",
      "Epoch 48/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5737 - acc: 0.8291\n",
      "Epoch 00048: val_loss improved from 0.08600 to 0.07362, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3162s 238ms/step - loss: 0.5737 - acc: 0.8291 - val_loss: 0.0736 - val_acc: 0.9925\n",
      "Epoch 49/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5698 - acc: 0.8297\n",
      "Epoch 00049: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.5698 - acc: 0.8297 - val_loss: 0.1145 - val_acc: 0.9875\n",
      "Epoch 50/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5681 - acc: 0.8302\n",
      "Epoch 00050: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3162s 238ms/step - loss: 0.5681 - acc: 0.8302 - val_loss: 0.1044 - val_acc: 0.9837\n",
      "Epoch 51/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5638 - acc: 0.8316\n",
      "Epoch 00051: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.5638 - acc: 0.8316 - val_loss: 0.0925 - val_acc: 0.9875\n",
      "Epoch 52/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5614 - acc: 0.8315\n",
      "Epoch 00052: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3161s 238ms/step - loss: 0.5614 - acc: 0.8315 - val_loss: 0.0811 - val_acc: 0.9850\n",
      "Epoch 53/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5588 - acc: 0.8326\n",
      "Epoch 00053: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.5588 - acc: 0.8326 - val_loss: 0.0747 - val_acc: 0.9887\n",
      "Epoch 54/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.8331\n",
      "Epoch 00054: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5564 - acc: 0.8331 - val_loss: 0.0899 - val_acc: 0.9875\n",
      "Epoch 55/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5517 - acc: 0.8339\n",
      "Epoch 00055: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5517 - acc: 0.8339 - val_loss: 0.0926 - val_acc: 0.9875\n",
      "Epoch 56/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5486 - acc: 0.8352\n",
      "Epoch 00056: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.5486 - acc: 0.8352 - val_loss: 0.0772 - val_acc: 0.9862\n",
      "Epoch 57/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.8359\n",
      "Epoch 00057: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.5462 - acc: 0.8359 - val_loss: 0.0942 - val_acc: 0.9875\n",
      "Epoch 58/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5450 - acc: 0.8366\n",
      "Epoch 00058: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.5450 - acc: 0.8366 - val_loss: 0.0752 - val_acc: 0.9912\n",
      "Epoch 59/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5435 - acc: 0.8367\n",
      "Epoch 00059: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.5435 - acc: 0.8367 - val_loss: 0.0893 - val_acc: 0.9900\n",
      "Epoch 60/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5388 - acc: 0.8381\n",
      "Epoch 00060: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.5388 - acc: 0.8381 - val_loss: 0.1249 - val_acc: 0.9875\n",
      "Epoch 61/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5358 - acc: 0.8381\n",
      "Epoch 00061: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.5358 - acc: 0.8381 - val_loss: 0.0793 - val_acc: 0.9887\n",
      "Epoch 62/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5326 - acc: 0.8396\n",
      "Epoch 00062: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3154s 238ms/step - loss: 0.5325 - acc: 0.8396 - val_loss: 0.0753 - val_acc: 0.9862\n",
      "Epoch 63/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5314 - acc: 0.8398\n",
      "Epoch 00063: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.5314 - acc: 0.8398 - val_loss: 0.1112 - val_acc: 0.9825\n",
      "Epoch 64/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5281 - acc: 0.8406\n",
      "Epoch 00064: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5281 - acc: 0.8406 - val_loss: 0.0912 - val_acc: 0.9875\n",
      "Epoch 65/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.8413\n",
      "Epoch 00065: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.5245 - acc: 0.8413 - val_loss: 0.1091 - val_acc: 0.9837\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5237 - acc: 0.8421\n",
      "Epoch 00066: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.5237 - acc: 0.8421 - val_loss: 0.1054 - val_acc: 0.9862\n",
      "Epoch 67/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5175 - acc: 0.8438\n",
      "Epoch 00067: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.5175 - acc: 0.8438 - val_loss: 0.0875 - val_acc: 0.9912\n",
      "Epoch 68/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5179 - acc: 0.8438\n",
      "Epoch 00068: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5179 - acc: 0.8437 - val_loss: 0.0826 - val_acc: 0.9900\n",
      "Epoch 69/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5182 - acc: 0.8430\n",
      "Epoch 00069: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5181 - acc: 0.8430 - val_loss: 0.0890 - val_acc: 0.9862\n",
      "Epoch 70/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5133 - acc: 0.8449\n",
      "Epoch 00070: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5133 - acc: 0.8449 - val_loss: 0.0814 - val_acc: 0.9912\n",
      "Epoch 71/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.8448\n",
      "Epoch 00071: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3160s 238ms/step - loss: 0.5112 - acc: 0.8448 - val_loss: 0.1136 - val_acc: 0.9825\n",
      "Epoch 72/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5114 - acc: 0.8450\n",
      "Epoch 00072: val_loss did not improve from 0.07362\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.5114 - acc: 0.8450 - val_loss: 0.0976 - val_acc: 0.9875\n",
      "Epoch 73/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5057 - acc: 0.8465\n",
      "Epoch 00073: val_loss improved from 0.07362 to 0.07280, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3164s 238ms/step - loss: 0.5057 - acc: 0.8465 - val_loss: 0.0728 - val_acc: 0.9912\n",
      "Epoch 74/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.8461\n",
      "Epoch 00074: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.5069 - acc: 0.8461 - val_loss: 0.0899 - val_acc: 0.9875\n",
      "Epoch 75/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5039 - acc: 0.8472\n",
      "Epoch 00075: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.5039 - acc: 0.8472 - val_loss: 0.0982 - val_acc: 0.9887\n",
      "Epoch 76/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.5010 - acc: 0.8483\n",
      "Epoch 00076: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.5010 - acc: 0.8483 - val_loss: 0.1059 - val_acc: 0.9812\n",
      "Epoch 77/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.8497\n",
      "Epoch 00077: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.4958 - acc: 0.8497 - val_loss: 0.0931 - val_acc: 0.9887\n",
      "Epoch 78/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8502\n",
      "Epoch 00078: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.4953 - acc: 0.8502 - val_loss: 0.0858 - val_acc: 0.9875\n",
      "Epoch 79/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8501\n",
      "Epoch 00079: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.4949 - acc: 0.8501 - val_loss: 0.0909 - val_acc: 0.9925\n",
      "Epoch 80/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4921 - acc: 0.8505\n",
      "Epoch 00080: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.4921 - acc: 0.8505 - val_loss: 0.1071 - val_acc: 0.9862\n",
      "Epoch 81/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4914 - acc: 0.8504\n",
      "Epoch 00081: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3154s 237ms/step - loss: 0.4914 - acc: 0.8504 - val_loss: 0.1319 - val_acc: 0.9875\n",
      "Epoch 82/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4856 - acc: 0.8520\n",
      "Epoch 00082: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3152s 237ms/step - loss: 0.4856 - acc: 0.8520 - val_loss: 0.0775 - val_acc: 0.9862\n",
      "Epoch 83/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8520\n",
      "Epoch 00083: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.4867 - acc: 0.8520 - val_loss: 0.1121 - val_acc: 0.9862\n",
      "Epoch 84/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4867 - acc: 0.8518\n",
      "Epoch 00084: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3153s 237ms/step - loss: 0.4867 - acc: 0.8518 - val_loss: 0.1069 - val_acc: 0.9875\n",
      "Epoch 85/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4825 - acc: 0.8529\n",
      "Epoch 00085: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.4825 - acc: 0.8529 - val_loss: 0.0890 - val_acc: 0.9925\n",
      "Epoch 86/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4787 - acc: 0.8542\n",
      "Epoch 00086: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.4787 - acc: 0.8542 - val_loss: 0.0893 - val_acc: 0.9900\n",
      "Epoch 87/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4779 - acc: 0.8542\n",
      "Epoch 00087: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.4780 - acc: 0.8542 - val_loss: 0.1088 - val_acc: 0.9900\n",
      "Epoch 88/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8543\n",
      "Epoch 00088: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3154s 238ms/step - loss: 0.4766 - acc: 0.8543 - val_loss: 0.0884 - val_acc: 0.9887\n",
      "Epoch 89/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8554\n",
      "Epoch 00089: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3154s 238ms/step - loss: 0.4748 - acc: 0.8554 - val_loss: 0.1202 - val_acc: 0.9837\n",
      "Epoch 90/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4743 - acc: 0.8550\n",
      "Epoch 00090: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.4743 - acc: 0.8550 - val_loss: 0.1139 - val_acc: 0.9900\n",
      "Epoch 91/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8550\n",
      "Epoch 00091: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.4734 - acc: 0.8550 - val_loss: 0.0846 - val_acc: 0.9925\n",
      "Epoch 92/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.8567\n",
      "Epoch 00092: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.4689 - acc: 0.8567 - val_loss: 0.0860 - val_acc: 0.9862\n",
      "Epoch 93/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8558\n",
      "Epoch 00093: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.4703 - acc: 0.8558 - val_loss: 0.0960 - val_acc: 0.9900\n",
      "Epoch 94/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8564\n",
      "Epoch 00094: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3155s 238ms/step - loss: 0.4679 - acc: 0.8564 - val_loss: 0.1000 - val_acc: 0.9912\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8578\n",
      "Epoch 00095: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3158s 238ms/step - loss: 0.4652 - acc: 0.8578 - val_loss: 0.1128 - val_acc: 0.9875\n",
      "Epoch 96/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8577\n",
      "Epoch 00096: val_loss did not improve from 0.07280\n",
      "13280/13280 [==============================] - 3156s 238ms/step - loss: 0.4651 - acc: 0.8577 - val_loss: 0.0886 - val_acc: 0.9862\n",
      "Epoch 97/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8579\n",
      "Epoch 00097: val_loss improved from 0.07280 to 0.06581, saving model to tbe_cnn_ytd_epoch_100.h5\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.4628 - acc: 0.8579 - val_loss: 0.0658 - val_acc: 0.9887\n",
      "Epoch 98/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.8591\n",
      "Epoch 00098: val_loss did not improve from 0.06581\n",
      "13280/13280 [==============================] - 3157s 238ms/step - loss: 0.4624 - acc: 0.8591 - val_loss: 0.1075 - val_acc: 0.9900\n",
      "Epoch 99/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8597\n",
      "Epoch 00099: val_loss did not improve from 0.06581\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.4588 - acc: 0.8597 - val_loss: 0.1108 - val_acc: 0.9887\n",
      "Epoch 100/100\n",
      "13279/13280 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8593\n",
      "Epoch 00100: val_loss did not improve from 0.06581\n",
      "13280/13280 [==============================] - 3159s 238ms/step - loss: 0.4587 - acc: 0.8593 - val_loss: 0.1114 - val_acc: 0.9900\n",
      "Common Function\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import model_3_branch\n",
    "import common_function\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "import os\n",
    "import asyncio\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.models import load_model, Model\n",
    "\n",
    "# Just disables the warning, doesn't enable AVX/FMA (no GPU)\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "epochs = 100\n",
    "l_rate = 1.0e-4\n",
    "decay = l_rate / epochs\n",
    "sgd = SGD(lr=l_rate, momentum=0.9, decay=decay, nesterov=False)\n",
    "batch_size = 32\n",
    "img_width, img_height = 24, 24\n",
    "path_data_set = './ytd'\n",
    "input_img, merged = model_3_branch.get_model(img_width, img_height)\n",
    "num_train_images = 424961  # training images: 424961  # total images: 605855\n",
    "file_path = 'tbe_cnn_ytd_epoch_100.h5'\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "\n",
    "############################################### Training Dataset #############################################################\n",
    "\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    flatten = Flatten()(merged)\n",
    "    dense = Dense(64)(flatten)\n",
    "    activation = Activation('softmax')(dense)\n",
    "    dropout = Dropout(0.5)(activation)\n",
    "    dense = Dense(1591)(dropout)\n",
    "    activation = Activation('softmax')(dense)\n",
    "\n",
    "    base_model = Model(input_img, activation)\n",
    "else:\n",
    "    base_model = load_model(file_path)\n",
    "    # base_model.load_weights(file_path)\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "train_generator_lr = datagen.flow_from_directory(\n",
    "    str(path_data_set + '/train'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator_lr = datagen.flow_from_directory(\n",
    "    str(path_data_set + '/validate'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print('training: ')\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    file_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='auto',\n",
    "    verbose=1\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = base_model.fit_generator(\n",
    "    generator=train_generator_lr,\n",
    "    steps_per_epoch=num_train_images // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator_lr,\n",
    "    validation_steps=800 // batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "common_func = common_function.CommonFunction()\n",
    "common_func.plot_training(history, 'TBE-CNN (3 Branch - 100 Epoch)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
